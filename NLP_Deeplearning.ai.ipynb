{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyassks/Learning-Content/blob/master/NLP_Deeplearning.ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Mxb6ppZVmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBcC8eC0ZqYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = ['PM Modi and President Trump talked on Kashmir issue in G20 summit','Trump said that Kashmir issue is Bilateral!!',\n",
        "           'My yoga classes were started again after a long break']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfVL0xVNZ5EE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8074f21e-3f2b-4e0c-a13c-67722fc1b526"
      },
      "source": [
        "token = Tokenizer(num_words = 50) # Tokenizer is a constructor, num words is the parameter which tells tokenizer to take top 50 words for tokenizing\n",
        "token.fit_on_texts(sentence) # token is an instance and fit_on_texts is the method \n",
        "word_dict = token.word_index # word_index property will put the sentence in dictionary form, key is the word and value is the index assigned to the unique words in corpus\n",
        "\n",
        "# Most repeated unique word is indexed at the first\n",
        "print(word_dict)  # punctuations are removed and upper case is scaled down to lower case\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'trump': 1, 'kashmir': 2, 'issue': 3, 'pm': 4, 'modi': 5, 'and': 6, 'president': 7, 'talked': 8, 'on': 9, 'in': 10, 'g20': 11, 'summit': 12, 'said': 13, 'that': 14, 'is': 15, 'bilateral': 16, 'my': 17, 'yoga': 18, 'classes': 19, 'were': 20, 'started': 21, 'again': 22, 'after': 23, 'a': 24, 'long': 25, 'break': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuOTBubgdTnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8044b9e-3775-4b75-aa84-02b6878f3b90"
      },
      "source": [
        "word_seq = token.texts_to_sequences(sentence) # this method will represent the values assigned to each word in corpus\n",
        "print(word_seq)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4, 5, 6, 7, 1, 8, 9, 2, 3, 10, 11, 12], [1, 13, 14, 2, 3, 15, 16], [17, 18, 19, 20, 21, 22, 23, 24, 25, 26]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nYmZ9q2gwL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "275a4075-02f0-4eb7-eabf-3609e2864bdc"
      },
      "source": [
        "test = ['Trump and Modi didnot talk about Pakistan or Imran Khan']\n",
        "test_seq = token.texts_to_sequences(test) # when you use a test data and convert into sequence, then only the words indexed before would be detected and new words will be ignored\n",
        "print(test_seq)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 6, 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFrLR8FFiOgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d9d6898f-e13d-4fba-f4bb-4d7d245f02de"
      },
      "source": [
        "'''\n",
        "To even recognise the unseen words, incorporate a key word oov_token in tokenizer object\n",
        "'''\n",
        "token = Tokenizer(num_words = 50, oov_token = '<OOV>') # OOV means Out of Vocabulary,its an initializer. token is an instance\n",
        "token.fit_on_texts(sentence) # token is an instance and fit_on_texts is the method \n",
        "word_dict = token.word_index # word_index property will put the sentence in dictionary form, key is the word and value is the index assigned to the unique words in corpus\n",
        "\n",
        "test_seq = token.texts_to_sequences(test)\n",
        "print(test_seq)\n",
        "print(word_dict)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 7, 6, 1, 1, 1, 1, 1, 1, 1]]\n",
            "{'<OOV>': 1, 'trump': 2, 'kashmir': 3, 'issue': 4, 'pm': 5, 'modi': 6, 'and': 7, 'president': 8, 'talked': 9, 'on': 10, 'in': 11, 'g20': 12, 'summit': 13, 'said': 14, 'that': 15, 'is': 16, 'bilateral': 17, 'my': 18, 'yoga': 19, 'classes': 20, 'were': 21, 'started': 22, 'again': 23, 'after': 24, 'a': 25, 'long': 26, 'break': 27}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhiTd96DjOeL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2c7d4db0-3882-4057-e759-6b6b1003e0d7"
      },
      "source": [
        "'''\n",
        "Padding will allow us to use sentences of different lengths\n",
        "Padding is mainly performed to maintain the uniformity of text sequences\n",
        "The size of sequence will be according to the longest sentence and padding is done after the sentence, default is 'pre'\n",
        "if you want sentences of max length of k words then use truncating parameter\n",
        "'''\n",
        "padding = pad_sequences(word_seq, padding = 'post') \n",
        "print(padding)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4  5  6  7  1  8  9  2  3 10 11 12]\n",
            " [ 1 13 14  2  3 15 16  0  0  0  0  0]\n",
            " [17 18 19 20 21 22 23 24 25 26  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}