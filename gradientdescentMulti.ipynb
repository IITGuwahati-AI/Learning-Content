{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # needed to plot 3-D surfaces\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "import utils \n",
    "\n",
    "# define the submission/grader object for this exercise\n",
    "grader = utils.Grader()\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]         y\n",
      "--------------------------\n",
      "    2104       3    399900\n",
      "    1600       3    329900\n",
      "    2400       3    369000\n",
      "    1416       2    232000\n",
      "    3000       4    539900\n",
      "    1985       4    299900\n",
      "    1534       3    314900\n",
      "    1427       3    198999\n",
      "    1380       3    212000\n",
      "    1494       3    242500\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = np.loadtxt('ex1data2.txt', delimiter=',')\n",
    "X = data[:, :2]\n",
    "y = data[:, 2]\n",
    "m = y.size\n",
    "\n",
    "# print out some data points\n",
    "print('{:>8s}{:>8s}{:>10s}'.format('X[:,0]', 'X[:, 1]', 'y'))\n",
    "print('-'*26)\n",
    "for i in range(10):\n",
    "    print('{:8.0f}{:8.0f}{:10.0f}'.format(X[i, 0], X[i, 1], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize(X):\n",
    "    \"\"\"\n",
    "    Normalizes the features in X. returns a normalized version of X where\n",
    "    the mean value of each feature is 0 and the standard deviation\n",
    "    is 1. This is often a good preprocessing step to do when working with\n",
    "    learning algorithms.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_norm : array_like\n",
    "        The normalized dataset of shape (m x n).\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    First, for each feature dimension, compute the mean of the feature\n",
    "    and subtract it from the dataset, storing the mean value in mu. \n",
    "    Next, compute the  standard deviation of each feature and divide\n",
    "    each feature by it's standard deviation, storing the standard deviation \n",
    "    in sigma. \n",
    "    \n",
    "    Note that X is a matrix where each column is a feature and each row is\n",
    "    an example. You needto perform the normalization separately for each feature. \n",
    "    \n",
    "    Hint\n",
    "    ----\n",
    "    You might find the 'np.mean' and 'np.std' functions useful.\n",
    "    \"\"\"\n",
    "    # You need to set these values correctly\n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    # =========================== YOUR CODE HERE =====================\n",
    "    for i in range(X.shape[1]):\n",
    "        sigma[i]=np.std(X[:,i])\n",
    "        mu[i]=np.sum(X[:,i])/X.shape[0]\n",
    "    \n",
    "    for j in range(X.shape[0]):\n",
    "        for k in range(X.shape[1]):\n",
    "            X_norm[j][k]=(X[j][k]-mu[k])/sigma[k]\n",
    "\n",
    "    # ================================================================\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed mean: [2000.68085106    3.17021277]\n",
      "Computed standard deviation: [7.86202619e+02 7.52842809e-01]\n"
     ]
    }
   ],
   "source": [
    "# call featureNormalize on the loaded data\n",
    "X_norm, mu, sigma = featureNormalize(X)\n",
    "\n",
    "print('Computed mean:', mu)\n",
    "print('Computed standard deviation:', sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add intercept term to X\n",
    "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCostMulti(X, y, theta):\n",
    "    \"\"\"\n",
    "    Compute cost for linear regression with multiple variables.\n",
    "    Computes the cost of using theta as the parameter for linear regression to fit the data points in X and y.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n+1).\n",
    "    \n",
    "    y : array_like\n",
    "        A vector of shape (m, ) for the values at a given data point.\n",
    "    \n",
    "    theta : array_like\n",
    "        The linear regression parameters. A vector of shape (n+1, )\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The value of the cost function. \n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Compute the cost of a particular choice of theta. You should set J to the cost.\n",
    "    \"\"\"\n",
    "    # Initialize some useful values\n",
    "    m = y.shape[0] # number of training examples\n",
    "    \n",
    "    # You need to return the following variable correctly\n",
    "    J = 0\n",
    "    \n",
    "    # ======================= YOUR CODE HERE ===========================\n",
    "    H=theta.dot(X.transpose())\n",
    "    sum=0\n",
    "    for element in range(len(H.transpose()-y)):\n",
    "        sum=sum+((H.transpose()-y)[element]*(H.transpose()-y)[element])\n",
    "        \n",
    "    J=sum/(2*m)   \n",
    "    \n",
    "    \n",
    "    # ==================================================================\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to learn theta.\n",
    "    Updates theta by taking num_iters gradient steps with learning rate alpha.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n+1).\n",
    "    \n",
    "    y : array_like\n",
    "        A vector of shape (m, ) for the values at a given data point.\n",
    "    \n",
    "    theta : array_like\n",
    "        The linear regression parameters. A vector of shape (n+1, )\n",
    "    \n",
    "    alpha : float\n",
    "        The learning rate for gradient descent. \n",
    "    \n",
    "    num_iters : int\n",
    "        The number of iterations to run gradient descent. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta : array_like\n",
    "        The learned linear regression parameters. A vector of shape (n+1, ).\n",
    "    \n",
    "    J_history : list\n",
    "        A python list for the values of the cost function after each iteration.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Peform a single gradient step on the parameter vector theta.\n",
    "\n",
    "    While debugging, it can be useful to print out the values of \n",
    "    the cost function (computeCost) and gradient here.\n",
    "    \"\"\"\n",
    "    # Initialize some useful values\n",
    "    m = y.shape[0] # number of training examples\n",
    "    \n",
    "    # make a copy of theta, which will be updated by gradient descent\n",
    "    theta = theta.copy()\n",
    "    \n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # ======================= YOUR CODE HERE ==========================\n",
    "        H=theta.dot(X.transpose())\n",
    "        \n",
    "        for j in range(theta.size):\n",
    "            theta[j]-=(alpha/m)*((H.transpose()-y).transpose()).dot(X[:,j])\n",
    "            \n",
    "        # =================================================================\n",
    "        \n",
    "        # save the cost J in every iteration\n",
    "        J_history.append(computeCostMulti(X, y, theta))\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[340412.56301439 109370.05670466  -6500.61509507]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta=np.zeros(X.shape[1])\n",
    "alpha=0.01\n",
    "num_iters=1500\n",
    "theta,J_history=gradientDescentMulti(X, y, theta, alpha, num_iters)\n",
    "print(theta)\n",
    "pyplot.plot(np.arange(len(J_history)), J_history, lw=2)  \n",
    "pyplot.xlabel('Number of iterations')\n",
    "pyplot.ylabel('Cost J')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price of a 1650 sq-ft, 3 br house (using gradient descent): $293098\n"
     ]
    }
   ],
   "source": [
    "# Estimate the price of a 1650 sq-ft, 3 br house\n",
    "# ======================= YOUR CODE HERE ===========================\n",
    "# Recall that the first column of X is all-ones. \n",
    "# Thus, it does not need to be normalized.\n",
    "sqft=1650\n",
    "numhouse=3\n",
    "\n",
    "price = 0   # You should change this\n",
    "\n",
    "norm_sqft=(sqft-mu[0])/sigma[0]\n",
    "norm_numhouse=(numhouse-mu[1])/sigma[1]\n",
    "\n",
    "price = theta[0] + (theta[1]*norm_sqft) + (theta[2]*norm_numhouse)\n",
    "\n",
    "# ===================================================================\n",
    "\n",
    "print('Predicted price of a 1650 sq-ft, 3 br house (using gradient descent): ${:.0f}'.format(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.loadtxt('ex1data2.txt', delimiter=',')\n",
    "X = data[:, :2]\n",
    "y = data[:, 2]\n",
    "m = y.size\n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalEqn(X, y):\n",
    "    \"\"\"\n",
    "    Computes the closed-form solution to linear regression using the normal equations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n+1).\n",
    "    \n",
    "    y : array_like\n",
    "        The value at each data point. A vector of shape (m, ).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta : array_like\n",
    "        Estimated linear regression parameters. A vector of shape (n+1, ).\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Complete the code to compute the closed form solution to linear\n",
    "    regression and put the result in theta.\n",
    "    \n",
    "    Hint\n",
    "    ----\n",
    "    Look up the function `np.linalg.pinv` for computing matrix inverse.\n",
    "    \"\"\"\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    \n",
    "    # ===================== YOUR CODE HERE ============================\n",
    "    \n",
    "    theta=((np.linalg.inv(((X.transpose()).dot(X)))).dot(X.transpose())).dot(y)\n",
    "\n",
    "    \n",
    "    # =================================================================\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta computed from the normal equations: [89597.9095428    139.21067402 -8738.01911233]\n",
      "Predicted price of a 1650 sq-ft, 3 br house (using normal equations): $293081\n"
     ]
    }
   ],
   "source": [
    "# Calculate the parameters from the normal equation\n",
    "theta = normalEqn(X, y);\n",
    "\n",
    "# Display normal equation's result\n",
    "print('Theta computed from the normal equations: {:s}'.format(str(theta)));\n",
    "\n",
    "# Estimate the price of a 1650 sq-ft, 3 br house\n",
    "# ====================== YOUR CODE HERE ======================\n",
    "\n",
    "price = 0 # You should change this\n",
    "\n",
    "sqft=1650\n",
    "numhouse=3\n",
    "\n",
    "price = theta[0] + (theta[1]*sqft) + (theta[2]*numhouse)\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "print('Predicted price of a 1650 sq-ft, 3 br house (using normal equations): ${:.0f}'.format(price))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
