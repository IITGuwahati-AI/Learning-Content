{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance of pca 1 is 0.19550174586532043\n",
      "variance of pca 2 is 0.17821024655134754\n",
      "variance of Feature 1 is 0.1955017458653203\n",
      "variance of Feature 2 is 0.1782102465513478\n",
      "variance of Feature 3 is 0.17406520208064483\n",
      "variance of Feature 4 is 0.10549293262888038\n",
      "variance of Feature 5 is 0.1001726612462652\n",
      "variance of Feature 6 is 0.09534420611515147\n",
      "variance of Feature 7 is 0.07929688407375128\n",
      "variance of Feature 8 is 0.04445224971507946\n",
      "variance of Feature 9 is 0.020609531993224163\n",
      "variance of Feature 10 is 0.006854339730335042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "VARAINCE OF FATURE 1 AND 2 MATCHES CLOSELY WITH THE BEST FEATURE VARANCE FROM PCA\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#loading data\n",
    "data = np.loadtxt('data1.txt',dtype=type(''))\n",
    "featuredata=data[1:,1:]\n",
    "labeldata = data[1:,0]\n",
    "final=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#covertin it as I used numpy to loadtxt rahter than csv as specified \n",
    "for row in featuredata :\n",
    "    row = list(map(float,row))\n",
    "    final.append(row)\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "#converting to a panda dataframe\n",
    "features=['1','2','3','4','5','6','7','8','9','10']\n",
    "fdf= pd.DataFrame(data=final,\n",
    "                    columns=features)\n",
    "\n",
    "    \n",
    "# this is Standardised data from our feature\n",
    "final= StandardScaler().fit_transform(fdf.loc[:,features].values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#using pca to convert in two feature\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(final)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#rhis is the labels \n",
    "target = pd.DataFrame(data=labeldata,\n",
    "                     columns=['labels'])\n",
    "\n",
    "\n",
    "\n",
    "#concating the features and labels dataframe\n",
    "finalDf = pd.concat([principalDf, target], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ploting the scatter for best fearues : It can be seen that this matches with graph of feature 1 and 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize = (8,8))\n",
    "# ax = fig.add_subplot(1,1,1) \n",
    "# ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "# ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "# ax.set_title('2 component PCA', fontsize = 20)\n",
    "# targets = ['1', '2']\n",
    "# colors = ['r', 'b']\n",
    "\n",
    "\n",
    "\n",
    "# for target, color in zip(targets,colors):\n",
    "#     indicesToKeep = finalDf['labels'] == target\n",
    "#     ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "#                , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "#                , c = color\n",
    "#                , s = 50)\n",
    "# ax.legend(targets)\n",
    "# ax.grid()\n",
    "\n",
    "\n",
    "\n",
    "#varince of the total data in our best features \n",
    "\n",
    "\n",
    "var2=pca.explained_variance_ratio_\n",
    "for i in range(2) :\n",
    "    print(\"variance of pca {} is {}\".format(i+1,var2[i]))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# just finding the vaince in all of our features \n",
    "pca2 = PCA()\n",
    "principalComponents = pca2.fit_transform(final)\n",
    "principalDfforall = pd.DataFrame(data = principalComponents)\n",
    "var=pca2.explained_variance_ratio_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#printing all ratios\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10) :\n",
    "    print(\"variance of Feature {} is {}\".format(i+1,var[i]))\n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "print('\\n'*5+'Varaince of fature 1 and 2 matches closely with the best feature varance from pca'.upper())\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
